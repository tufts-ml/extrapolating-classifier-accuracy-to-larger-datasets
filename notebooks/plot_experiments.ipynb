{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from models import *\n",
    "from priors import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_experiment(df, labels):\n",
    "    # Take mean of each random seed at each dataset size\n",
    "    df = df.groupby('n').agg(lambda x: list(x))\n",
    "    df.test_auroc = df.test_auroc.apply(lambda x: np.mean(x, axis=0))\n",
    "    df.random_state = df.random_state.apply(lambda x: 'mean')\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    ncols = len(labels) if len(labels) < 4 else 4\n",
    "    nrows = math.ceil(len(labels)/4)\n",
    "    fig, axs = plt.subplots(ncols=ncols, nrows=nrows, figsize=(ncols*4, nrows*3), dpi=300)\n",
    "    \n",
    "    mle_rmse = np.zeros(len(labels))\n",
    "    gp_rmse = np.zeros(len(labels))\n",
    "    baseline1 = np.zeros(len(labels))\n",
    "    baseline2 = np.zeros(len(labels))\n",
    "    likelihoods = np.zeros(len(labels))\n",
    "    coverage = np.zeros(len(labels))\n",
    "    \n",
    "    for label_index, _ in enumerate(labels):\n",
    "        # Plot data\n",
    "        temp_df = df[df.random_state=='mean']\n",
    "        np.array(axs).flatten()[label_index]\\\n",
    "        .scatter(temp_df[temp_df.n<=360].n.to_numpy(),\n",
    "                 np.array(temp_df[temp_df.n<=360].test_auroc.to_list())[:,label_index],\n",
    "                 color='black',\n",
    "                 alpha=1.0,\n",
    "                 label='Initial subsets')\n",
    "        np.array(axs).flatten()[label_index]\\\n",
    "        .scatter(temp_df[temp_df.n>360].n.to_numpy(),\n",
    "                 np.array(temp_df[temp_df.n>360].test_auroc.to_list())[:,label_index],\n",
    "                 color='black',\n",
    "                 alpha=0.3,\n",
    "                 label='Ground truth')\n",
    "        # Split data\n",
    "        X_train, y_train, X_test, y_test = split_df(df, label_index)\n",
    "        # Train power law model\n",
    "        #\"\"\"\n",
    "        model = train_Arctan(X_train, y_train)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            #float(torch.max(X_test))\n",
    "            observed_pred = model(torch.linspace(200, 30000, 1000))\n",
    "        np.array(axs).flatten()[label_index]\\\n",
    "        .plot(np.linspace(200, 30000, 1000), observed_pred.numpy(), color='#d62728', label='Power law')\n",
    "        # RMSE\n",
    "        mle_rmse[label_index]\\\n",
    "        = rmse(y_test.detach().numpy(), model(X_test).detach().numpy())        \n",
    "        #\"\"\"\n",
    "        # Train Gaussian process\n",
    "        #\"\"\"\n",
    "        likelihood, model = train_GPArctan(X_train, y_train)\n",
    "        likelihood.eval()\n",
    "        model.eval()\n",
    "        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "            observed_pred = likelihood(model(torch.linspace(200, 30000, 1000)))\n",
    "        lower, upper = truncated_normal_uncertainty(observed_pred.mean.numpy(), observed_pred.stddev.numpy())        \n",
    "        #lower, upper = observed_pred.mean.numpy()-(3*observed_pred.stddev.numpy()), observed_pred.mean.numpy()+(3*observed_pred.stddev.numpy())   \n",
    "        np.array(axs).flatten()[label_index]\\\n",
    "        .plot(np.linspace(200, 30000, 1000), observed_pred.mean.numpy(), color='#1f77b4', label='Gaussian process (ours)')\n",
    "        np.array(axs).flatten()[label_index]\\\n",
    "        .fill_between(np.linspace(200, 30000, 1000), lower, upper, color='#1f77b4', alpha=0.1)\n",
    "        # RMSE\n",
    "        gp_rmse[label_index]\\\n",
    "        = rmse(y_test.detach().numpy(), model(X_test).mean.detach().numpy())\n",
    "        # Log-likelihood\n",
    "        baseline1[label_index] = uniform_likelihood(y_test, 0.5)\n",
    "        baseline2[label_index] = uniform_likelihood(y_test, float(torch.min(y_train)))\n",
    "        log_likelihood = truncated_normal_likelihood(y_test, likelihood(model(X_test)).mean.detach().numpy(), likelihood(model(X_test)).stddev.detach().numpy())\n",
    "        likelihoods[label_index] = log_likelihood\n",
    "        # Coverage\n",
    "        lower, upper = truncated_normal_uncertainty(likelihood(model(X_test)).mean.detach().numpy(), likelihood(model(X_test)).stddev.detach().numpy())   \n",
    "        coverage[label_index]\\\n",
    "        = calc_coverage(y_test.detach().numpy(), lower, upper)        \n",
    "        #\"\"\"\n",
    "\n",
    "        # Formatting\n",
    "        np.array(axs).flatten()[label_index]\\\n",
    "        .set_ylim([0.5, 1.0])\n",
    "        np.array(axs).flatten()[label_index]\\\n",
    "        .set_xscale('log')\n",
    "        np.array(axs).flatten()[label_index]\\\n",
    "        .set_xlabel('Number of training samples (log-scale)')\n",
    "        np.array(axs).flatten()[label_index]\\\n",
    "        .set_ylabel('{} AUROC'.format(labels[label_index]))\n",
    "        #np.array(axs).flatten()[label_index]\\\n",
    "        #.legend(loc='lower right')\n",
    "        np.array(axs).flatten()[label_index]\\\n",
    "        .legend()\n",
    "        np.array(axs).flatten()[label_index]\\\n",
    "        .grid()\n",
    "    #print('Power law RMSE median: {:.2f}, minimum: {:.2f}, maximum: {:.2f}'.format(np.median(mle_rmse*100), np.min(mle_rmse*100), np.max(mle_rmse*100)))\n",
    "    #print('GP RMSE median: {:.2f}, minimum: {:.2f}, maximum: {:.2f}'.format(np.median(gp_rmse*100), np.min(gp_rmse*100), np.max(gp_rmse*100)))\n",
    "    #print('Uniform [0.5, 1] log-likelihood median: {:.2f}, minimum: {:.2f}, maximum: {:.2f}'.format(np.median(baseline1), np.min(baseline1), np.max(baseline1)))\n",
    "    #print('Uniform [max(v(n_{{1:m}})), 1] log-likelihood median: {:.2f}, minimum: {:.2f}, maximum: {:.2f}'.format(np.median(baseline2), np.min(baseline2), np.max(baseline2)))\n",
    "    #print('GP log-likelihood median: {:.2f}, minimum: {:.2f}, maximum: {:.2f}'.format(np.median(likelihoods), np.min(likelihoods), np.max(likelihoods)))\n",
    "    #print('GP coverage median: {:.2f}%, minimum: {:.2f}%, maximum: {:.2f}%'.format(np.median(coverage*100), np.min(coverage*100), np.max(coverage*100)))\n",
    "    print('Power law RMSE: {}'.format(mle_rmse*100))\n",
    "    print('GP RMSE: {}'.format(gp_rmse*100))\n",
    "    print('Uniform [0.5, 1] log-likelihood: {}'.format(baseline1))\n",
    "    print('Uniform [min(v(n_{{1:m}})), 1] log-likelihood: {}'.format(baseline2))\n",
    "    print('GP log-likelihood: {}'.format(likelihoods))\n",
    "    print('GP coverage: {}'.format(coverage*100))\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChestX-ray14 (short range)\n",
    "df = load_experiment('/cluster/home/eharve06/extrapolating-classifier-accuracy-to-bigger-datasets/experiments/ChestX-ray14_short_range.csv')\n",
    "plot_experiment(df, ['Atelectasis', 'Effusion', 'Infiltration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChestX-ray14 (long range)\n",
    "df = load_experiment('/cluster/home/eharve06/extrapolating-classifier-accuracy-to-bigger-datasets/experiments/ChestX-ray14_long_range.csv')\n",
    "plot_experiment(df, ['Atelectasis', 'Effusion', 'Infiltration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chest X-Ray (short range)\n",
    "df = load_experiment('/cluster/home/eharve06/extrapolating-classifier-accuracy-to-bigger-datasets/experiments/Chest_X-Ray_short_range.csv')\n",
    "plot_experiment(df, ['Bacteria', 'Virus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chest X-Ray (long range)\n",
    "df = load_experiment('/cluster/home/eharve06/extrapolating-classifier-accuracy-to-bigger-datasets/experiments/Chest_X-Ray_long_range.csv')\n",
    "plot_experiment(df, ['Bacteria', 'Virus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUSI (short range)\n",
    "df = load_experiment('/cluster/home/eharve06/extrapolating-classifier-accuracy-to-bigger-datasets/experiments/BUSI_short_range.csv')\n",
    "plot_experiment(df, ['Normal', 'Benign', 'Malignant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OASIS-3 (short range)\n",
    "df = load_experiment('/cluster/home/eharve06/extrapolating-classifier-accuracy-to-bigger-datasets/experiments/OASIS-3_short_range.csv')\n",
    "plot_experiment(df, ['Alzheimerâ€™s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "palette = sns.color_palette().as_hex()\n",
    "fourth_color = palette[4]\n",
    "print(fourth_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_range_experiments = ['/cluster/home/eharve06/extrapolating-classifier-accuracy-to-bigger-datasets/experiments/ChestX-ray14_short_range.csv',\n",
    "                           '/cluster/home/eharve06/extrapolating-classifier-accuracy-to-bigger-datasets/experiments/Chest_X-Ray_short_range.csv',\n",
    "                           '/cluster/home/eharve06/extrapolating-classifier-accuracy-to-bigger-datasets/experiments/BUSI_short_range.csv']\n",
    "short_range_labels = [['Atelectasis', 'Effusion', 'Infiltration'],\n",
    "                      ['Bacteria', 'Virus'],\n",
    "                      ['Normal', 'Benign', 'Malignant']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_performance(df):\n",
    "    # Take mean of each random seed at each dataset size\n",
    "    df = df.groupby('n').agg(lambda x: list(x))\n",
    "    df.test_auroc = df.test_auroc.apply(lambda x: np.mean(x, axis=0))\n",
    "    df.random_state = df.random_state.apply(lambda x: 'mean')\n",
    "    df = df.reset_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short range\n",
    "ncols, nrows = 4, 6\n",
    "fig, axs = plt.subplots(ncols=ncols, nrows=nrows, figsize=(ncols*4, nrows*3), sharex=True, sharey=True, dpi=300)\n",
    "for dataset_index, (path, labels) in enumerate(zip(short_range_experiments, short_range_labels)):\n",
    "    df = load_experiment(path)\n",
    "    df = mean_performance(df)\n",
    "    for label_index, _ in enumerate(labels):\n",
    "        # Plot data\n",
    "        figure_index = dataset_index*4+label_index\n",
    "        temp_df = df[df.random_state=='mean']\n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .scatter(temp_df[temp_df.n<=360].n.to_numpy(),\n",
    "                 np.array(temp_df[temp_df.n<=360].test_auroc.to_list())[:,label_index],\n",
    "                 color='black',\n",
    "                 alpha=1.0,\n",
    "                 label='Initial subsets')\n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .scatter(temp_df[temp_df.n>360].n.to_numpy(),\n",
    "                 np.array(temp_df[temp_df.n>360].test_auroc.to_list())[:,label_index],\n",
    "                 color='black',\n",
    "                 alpha=0.3,\n",
    "                 label='Ground truth')\n",
    "        # Split data\n",
    "        X_train, y_train, X_test, y_test = split_df(df, label_index)\n",
    "        # Train Gaussian process\n",
    "        likelihood, model = train_GPPowerLaw(X_train, y_train)\n",
    "        likelihood.eval()\n",
    "        model.eval()\n",
    "        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "            observed_pred = likelihood(model(torch.linspace(100, 30000, 1000)))\n",
    "        lower, upper = truncated_normal_uncertainty(observed_pred.mean.numpy(), observed_pred.stddev.numpy())        \n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .plot(np.linspace(100, 30000, 1000), observed_pred.mean.numpy(), color='#1f77b4', label='Power law (ours)')\n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .fill_between(np.linspace(100, 30000, 1000), lower, upper, color='#1f77b4', alpha=0.1)\n",
    "        # Train Gaussian process\n",
    "        likelihood, model = train_GPArctan(X_train, y_train)\n",
    "        likelihood.eval()\n",
    "        model.eval()\n",
    "        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "            observed_pred = likelihood(model(torch.linspace(100, 30000, 1000)))\n",
    "        lower, upper = truncated_normal_uncertainty(observed_pred.mean.numpy(), observed_pred.stddev.numpy())        \n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .plot(np.linspace(100, 30000, 1000), observed_pred.mean.numpy(), color='#d62728', label='Arctan (ours)')\n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .fill_between(np.linspace(100, 30000, 1000), lower, upper, color='#d62728', alpha=0.1)\n",
    "        # Formatting\n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .set_xlim([100, 30000])\n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .set_ylim([0.5, 1.0])\n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .set_xscale('log')\n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .set_xlabel('Number of training samples')\n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .set_ylabel('{} AUROC'.format(labels[label_index]))\n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .legend()\n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .grid()\n",
    "    for index in range(len(labels),4):\n",
    "        figure_index = dataset_index*4+index\n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .imshow([[1]], cmap='gray', vmin=0, vmax=1)\n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .set_axis_off()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_range_experiments = ['/cluster/home/eharve06/extrapolating-classifier-accuracy-to-bigger-datasets/experiments/ChestX-ray14_long_range.csv',\n",
    "                          '/cluster/home/eharve06/extrapolating-classifier-accuracy-to-bigger-datasets/experiments/Chest_X-Ray_long_range.csv']\n",
    "long_range_labels = [['Atelectasis', 'Effusion', 'Infiltration'],\n",
    "                     ['Bacteria', 'Virus']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long range\n",
    "ncols, nrows = 4, 3\n",
    "fig, axs = plt.subplots(ncols=ncols, nrows=nrows, figsize=(ncols*4, nrows*3), dpi=300)\n",
    "for dataset_index, (path, labels) in enumerate(zip(long_range_experiments, long_range_labels)):\n",
    "    df = load_experiment(path)\n",
    "    df = mean_performance(df)\n",
    "    for label_index, _ in enumerate(labels):\n",
    "        # Plot data\n",
    "        figure_index = dataset_index*4+label_index\n",
    "        temp_df = df[df.random_state=='mean']\n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .scatter(temp_df[temp_df.n<=360].n.to_numpy(),\n",
    "                 np.array(temp_df[temp_df.n<=360].test_auroc.to_list())[:,label_index],\n",
    "                 color='black',\n",
    "                 alpha=1.0,\n",
    "                 label='Initial subsets')\n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .scatter(temp_df[temp_df.n>360].n.to_numpy(),\n",
    "                 np.array(temp_df[temp_df.n>360].test_auroc.to_list())[:,label_index],\n",
    "                 color='black',\n",
    "                 alpha=0.3,\n",
    "                 label='Ground truth')\n",
    "        # Split data\n",
    "        X_train, y_train, X_test, y_test = split_df(df, label_index)\n",
    "        # Train Gaussian process\n",
    "        likelihood, model = train_GPPowerLaw(X_train, y_train)\n",
    "        likelihood.eval()\n",
    "        model.eval()\n",
    "        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "            observed_pred = likelihood(model(torch.linspace(100, 30000, 1000)))\n",
    "        lower, upper = truncated_normal_uncertainty(observed_pred.mean.numpy(), observed_pred.stddev.numpy())        \n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .plot(np.linspace(100, 30000, 1000), observed_pred.mean.numpy(), color='#1f77b4', label='Power law (ours)')\n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .fill_between(np.linspace(100, 30000, 1000), lower, upper, color='#1f77b4', alpha=0.1)\n",
    "        # Train Gaussian process\n",
    "        likelihood, model = train_GPArctan(X_train, y_train)\n",
    "        likelihood.eval()\n",
    "        model.eval()\n",
    "        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "            observed_pred = likelihood(model(torch.linspace(100, 30000, 1000)))\n",
    "        lower, upper = truncated_normal_uncertainty(observed_pred.mean.numpy(), observed_pred.stddev.numpy())        \n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .plot(np.linspace(100, 30000, 1000), observed_pred.mean.numpy(), color='#d62728', label='Arctan (ours)')\n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .fill_between(np.linspace(100, 30000, 1000), lower, upper, color='#d62728', alpha=0.1)\n",
    "        # Formatting\n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .set_xlim([100, 30000])\n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .set_ylim([0.5, 1.0])\n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .set_xscale('log')\n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .set_xlabel('Number of training samples')\n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .set_ylabel('{} AUROC'.format(labels[label_index]))\n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .legend()\n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .grid()\n",
    "        np.array(axs).flatten()[label_index]\\\n",
    "        .legend(loc='lower right')\n",
    "    for index in range(len(labels),4):\n",
    "        figure_index = dataset_index*4+index\n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .imshow([[1]], cmap='gray', vmin=0, vmax=1)\n",
    "        np.array(axs).flatten()[figure_index]\\\n",
    "        .set_axis_off()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdl_2022f_env",
   "language": "python",
   "name": "bdl_2022f_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
