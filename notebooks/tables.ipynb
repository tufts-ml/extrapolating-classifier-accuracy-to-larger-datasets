{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "import os\n",
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = '/cluster/home/eharve06/extrapolating-classifier-accuracy-to-bigger-datasets'\n",
    "experiments_path = os.path.join(repo_path, 'experiments')\n",
    "models_path = os.path.join(repo_path, 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset                ChestX-ray14\n",
      "Label                   Atelectasis\n",
      "Power law                  0.343932\n",
      "GP power law (ours)        0.328503\n",
      "Arctan                     0.397446\n",
      "GP arctan (ours)           0.396337\n",
      "Name: 0, dtype: object\n",
      "Dataset                ChestX-ray14\n",
      "Label                      Effusion\n",
      "Power law                  0.673123\n",
      "GP power law (ours)        0.859261\n",
      "Arctan                     0.670878\n",
      "GP arctan (ours)            0.81119\n",
      "Name: 1, dtype: object\n",
      "Dataset                ChestX-ray14\n",
      "Label                  Infiltration\n",
      "Power law                  0.320141\n",
      "GP power law (ours)        0.433044\n",
      "Arctan                      2.26379\n",
      "GP arctan (ours)           2.191777\n",
      "Name: 2, dtype: object\n",
      "Dataset                Chest_X-Ray\n",
      "Label                    Bacterial\n",
      "Power law                 0.211795\n",
      "GP power law (ours)        0.22525\n",
      "Arctan                    0.164136\n",
      "GP arctan (ours)          0.168549\n",
      "Name: 3, dtype: object\n",
      "Dataset                Chest_X-Ray\n",
      "Label                        Viral\n",
      "Power law                 1.012443\n",
      "GP power law (ours)       1.045517\n",
      "Arctan                    1.094923\n",
      "GP arctan (ours)          1.095039\n",
      "Name: 4, dtype: object\n",
      "Dataset                    BUSI\n",
      "Label                    Normal\n",
      "Power law              0.705307\n",
      "GP power law (ours)    0.704885\n",
      "Arctan                  0.70459\n",
      "GP arctan (ours)       0.704532\n",
      "Name: 5, dtype: object\n",
      "Dataset                    BUSI\n",
      "Label                    Benign\n",
      "Power law              1.538792\n",
      "GP power law (ours)    1.543566\n",
      "Arctan                 1.542518\n",
      "GP arctan (ours)       1.547202\n",
      "Name: 6, dtype: object\n",
      "Dataset                     BUSI\n",
      "Label                  Malignant\n",
      "Power law               1.002652\n",
      "GP power law (ours)     1.002661\n",
      "Arctan                  1.003124\n",
      "GP arctan (ours)        1.002617\n",
      "Name: 7, dtype: object\n",
      "Dataset                  TMED-2\n",
      "Label                      PLAX\n",
      "Power law              0.123596\n",
      "GP power law (ours)    0.126249\n",
      "Arctan                 0.261377\n",
      "GP arctan (ours)       0.260767\n",
      "Name: 8, dtype: object\n",
      "Dataset                  TMED-2\n",
      "Label                      PSAX\n",
      "Power law              0.446938\n",
      "GP power law (ours)    0.447022\n",
      "Arctan                 0.450091\n",
      "GP arctan (ours)       0.450916\n",
      "Name: 9, dtype: object\n",
      "Dataset                  TMED-2\n",
      "Label                       A4C\n",
      "Power law              0.407778\n",
      "GP power law (ours)    0.408177\n",
      "Arctan                 0.720938\n",
      "GP arctan (ours)       0.721188\n",
      "Name: 10, dtype: object\n",
      "Dataset                  TMED-2\n",
      "Label                       A2C\n",
      "Power law              2.177394\n",
      "GP power law (ours)    2.173807\n",
      "Arctan                 0.081304\n",
      "GP arctan (ours)       0.081988\n",
      "Name: 11, dtype: object\n",
      "Dataset                    OASIS-3\n",
      "Label                  Alzheimer’s\n",
      "Power law                 1.561345\n",
      "GP power law (ours)       1.562833\n",
      "Arctan                    1.038927\n",
      "GP arctan (ours)          1.046315\n",
      "Name: 12, dtype: object\n",
      "Dataset                   Pilot\n",
      "Label                       WMD\n",
      "Power law              1.456978\n",
      "GP power law (ours)    1.426679\n",
      "Arctan                 1.472192\n",
      "GP arctan (ours)       1.441711\n",
      "Name: 13, dtype: object\n",
      "Dataset                   Pilot\n",
      "Label                       CBI\n",
      "Power law              1.308896\n",
      "GP power law (ours)    1.338415\n",
      "Arctan                 1.303223\n",
      "GP arctan (ours)       1.323496\n",
      "Name: 14, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17382/2222112116.py:40: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  f.write(rounded_df.to_latex(index=False))\n"
     ]
    }
   ],
   "source": [
    "dataset_names = ['ChestX-ray14', 'Chest_X-Ray', 'BUSI', 'TMED-2', 'OASIS-3', 'Pilot']\n",
    "forecasting = 'short_range'\n",
    "labels = [['Atelectasis', 'Effusion', 'Infiltration'],\n",
    "          ['Bacterial', 'Viral'],\n",
    "          ['Normal', 'Benign', 'Malignant'],\n",
    "          ['PLAX', 'PSAX', 'A4C', 'A2C'],\n",
    "          ['Alzheimer’s'],\n",
    "          ['WMD', 'CBI']]\n",
    "models = ['PowerLaw', 'GPPowerLaw', 'Arctan', 'GPArctan']\n",
    "\n",
    "row_index = -1\n",
    "columns = ['Dataset', 'Label', 'Power law', 'GP power law (ours)', 'Arctan', 'GP arctan (ours)']\n",
    "metrics_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for dataset_index, dataset_name in enumerate(dataset_names):\n",
    "    df = utils.load_experiment(os.path.join(experiments_path, '{}_{}.csv'.format(dataset_name, forecasting)))\n",
    "    # Take mean of each random seed at each dataset size\n",
    "    df = df.groupby('n').agg(lambda x: list(x))\n",
    "    df.test_auroc = df.test_auroc.apply(lambda x: np.mean(x, axis=0))\n",
    "    df.random_state = df.random_state.apply(lambda x: 'mean')\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    for label_index, label_name in enumerate(labels[dataset_index]):\n",
    "        row_index = row_index+1\n",
    "        metrics = [None]*len(models)\n",
    "        # Plot data\n",
    "        X_train, y_train, X_test, y_test = utils.split_df(df, index=label_index)\n",
    "        # Load model\n",
    "        for model_index, model_name in enumerate(models):\n",
    "            model_filename = '{}_{}_{}.pt'.format(dataset_name, label_name, model_name)\n",
    "            model_filepath = os.path.join(models_path, model_filename)\n",
    "            model_objects = utils.load_model(model_name, model_filepath, X_train, y_train)\n",
    "            metrics[model_index] = utils.print_metrics(model_objects, y_train, X_test, y_test, verbose=0)\n",
    "        row = [dataset_name, label_name, metrics[0][0], metrics[1][0], metrics[2][0], metrics[3][0]]\n",
    "        metrics_df.loc[row_index] = row\n",
    "        print(metrics_df.loc[row_index])\n",
    "    \n",
    "rounded_df = metrics_df.round(3)\n",
    "with open('rmse_short.tex', 'w') as f:\n",
    "    f.write(rounded_df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset                ChestX-ray14\n",
      "Label                   Atelectasis\n",
      "Power law                  1.854585\n",
      "GP power law (ours)        1.721867\n",
      "Arctan                     2.948669\n",
      "GP arctan (ours)           2.946587\n",
      "Name: 0, dtype: object\n",
      "Dataset                ChestX-ray14\n",
      "Label                      Effusion\n",
      "Power law                  3.970832\n",
      "GP power law (ours)        3.505888\n",
      "Arctan                       3.9656\n",
      "GP arctan (ours)           3.513107\n",
      "Name: 1, dtype: object\n",
      "Dataset                ChestX-ray14\n",
      "Label                  Infiltration\n",
      "Power law                  1.616261\n",
      "GP power law (ours)        2.078804\n",
      "Arctan                    15.349708\n",
      "GP arctan (ours)          13.469627\n",
      "Name: 2, dtype: object\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/cluster/home/eharve06/extrapolating-classifier-accuracy-to-bigger-datasets/models/Chest_X-Ray_Bacteria_PowerLaw.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m     model_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(dataset_name, label_name, model_name)\n\u001b[1;32m     28\u001b[0m     model_filepath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(models_path, model_filename)\n\u001b[0;32m---> 29\u001b[0m     model_objects \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_filepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     metrics[model_index] \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mprint_metrics(model_objects, y_train, X_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     31\u001b[0m row \u001b[38;5;241m=\u001b[39m [dataset_name, label_name, metrics[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], metrics[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m], metrics[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m0\u001b[39m], metrics[\u001b[38;5;241m3\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n",
      "File \u001b[0;32m~/extrapolating-classifier-accuracy-to-bigger-datasets/src/utils.py:171\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, path, X_train, y_train)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     model \u001b[38;5;241m=\u001b[39m model_class(y_train[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m--> 171\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    172\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model,\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl_2022f_env/lib/python3.8/site-packages/torch/serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    697\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 699\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl_2022f_env/lib/python3.8/site-packages/torch/serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl_2022f_env/lib/python3.8/site-packages/torch/serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/cluster/home/eharve06/extrapolating-classifier-accuracy-to-bigger-datasets/models/Chest_X-Ray_Bacteria_PowerLaw.pt'"
     ]
    }
   ],
   "source": [
    "dataset_names = ['ChestX-ray14', 'Chest_X-Ray', 'TMED-2']\n",
    "forecasting = 'long_range'\n",
    "labels = [['Atelectasis', 'Effusion', 'Infiltration'],\n",
    "          ['Bacteria', 'Virus'],\n",
    "          ['PLAX', 'PSAX', 'A4C', 'A2C']]\n",
    "models = ['PowerLaw', 'GPPowerLaw', 'Arctan', 'GPArctan']\n",
    "\n",
    "row_index = -1\n",
    "columns = ['Dataset', 'Label', 'Power law', 'GP power law (ours)', 'Arctan', 'GP arctan (ours)']\n",
    "metrics_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for dataset_index, dataset_name in enumerate(dataset_names):\n",
    "    df = utils.load_experiment(os.path.join(experiments_path, '{}_{}.csv'.format(dataset_name, forecasting)))\n",
    "    # Take mean of each random seed at each dataset size\n",
    "    df = df.groupby('n').agg(lambda x: list(x))\n",
    "    df.test_auroc = df.test_auroc.apply(lambda x: np.mean(x, axis=0))\n",
    "    df.random_state = df.random_state.apply(lambda x: 'mean')\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    for label_index, label_name in enumerate(labels[dataset_index]):\n",
    "        row_index = row_index+1\n",
    "        metrics = [None]*len(models)\n",
    "        # Plot data\n",
    "        X_train, y_train, X_test, y_test = utils.split_df(df, index=label_index)\n",
    "        # Load model\n",
    "        for model_index, model_name in enumerate(models):\n",
    "            model_filename = '{}_{}_{}.pt'.format(dataset_name, label_name, model_name)\n",
    "            model_filepath = os.path.join(models_path, model_filename)\n",
    "            model_objects = utils.load_model(model_name, model_filepath, X_train, y_train)\n",
    "            metrics[model_index] = utils.print_metrics(model_objects, y_train, X_test, y_test, verbose=0)\n",
    "        row = [dataset_name, label_name, metrics[0][0], metrics[1][0], metrics[2][0], metrics[3][0]]\n",
    "        metrics_df.loc[row_index] = row\n",
    "        print(metrics_df.loc[row_index])\n",
    "    \n",
    "rounded_df = metrics_df.round(3)\n",
    "with open('rmse_long.tex', 'w') as f:\n",
    "    f.write(rounded_df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = ['ChestX-ray14', 'Chest_X-Ray', 'BUSI', 'TMED-2', 'OASIS-3', 'Pilot']\n",
    "labels = [['Atelectasis', 'Effusion', 'Infiltration'],\n",
    "          ['Bacteria', 'Virus'],\n",
    "          ['Normal', 'Benign', 'Malignant'],\n",
    "          ['PLAX', 'PSAX', 'A4C', 'A2C'],\n",
    "          ['Alzheimer’s'],\n",
    "          ['WMD', 'CBI']]\n",
    "models = ['GPPowerLaw', 'GPArctan']\n",
    "\n",
    "row_index = -1\n",
    "columns = ['Dataset', 'Label', 'Power law', 'GP power law (ours)', 'Arctan', 'GP arctan (ours)']\n",
    "metrics_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for dataset_index, dataset_name in enumerate(dataset_names):\n",
    "    for label_index, label_name in enumerate(labels[dataset_index]):\n",
    "        row_index = row_index+1\n",
    "        metrics = [None]*(2*len(models))\n",
    "        \n",
    "        df = utils.load_experiment(os.path.join(experiments_path, '{}_short_range.csv'.format(dataset_name)))\n",
    "        # Take mean of each random seed at each dataset size\n",
    "        df = df.groupby('n').agg(lambda x: list(x))\n",
    "        df.test_auroc = df.test_auroc.apply(lambda x: np.mean(x, axis=0))\n",
    "        df.random_state = df.random_state.apply(lambda x: 'mean')\n",
    "        df = df.reset_index()\n",
    "        \n",
    "        # Plot data\n",
    "        X_train, y_train, X_test, y_test = utils.split_df(df, index=label_index)\n",
    "        # Load model\n",
    "        for model_index, model_name in enumerate(models):\n",
    "            model_filename = '{}_{}_{}.pt'.format(dataset_name, label_name, model_name)\n",
    "            model_filepath = os.path.join(models_path, model_filename)\n",
    "            model_objects = utils.load_model(model_name, model_filepath, X_train, y_train)\n",
    "            metrics[model_index] = utils.print_metrics(model_objects, y_train, X_test, y_test, verbose=0)\n",
    "            \n",
    "        if dataset_name in ['ChestX-ray14', 'Chest_X-Ray', 'TMED-2']:\n",
    "            \n",
    "            df = utils.load_experiment(os.path.join(experiments_path, '{}_long_range.csv'.format(dataset_name)))\n",
    "            # Take mean of each random seed at each dataset size\n",
    "            df = df.groupby('n').agg(lambda x: list(x))\n",
    "            df.test_auroc = df.test_auroc.apply(lambda x: np.mean(x, axis=0))\n",
    "            df.random_state = df.random_state.apply(lambda x: 'mean')\n",
    "            df = df.reset_index()\n",
    "\n",
    "            # Plot data\n",
    "            X_train, y_train, X_test, y_test = utils.split_df(df, index=label_index)\n",
    "            # Load model\n",
    "            for model_index, model_name in enumerate(models):\n",
    "                model_filename = '{}_{}_{}.pt'.format(dataset_name, label_name, model_name)\n",
    "                model_filepath = os.path.join(models_path, model_filename)\n",
    "                model_objects = utils.load_model(model_name, model_filepath, X_train, y_train)\n",
    "                metrics[2+model_index] = utils.print_metrics(model_objects, y_train, X_test, y_test, verbose=0)\n",
    "        \n",
    "            row = [dataset_name, label_name, metrics[0][4], metrics[1][4], metrics[2][4], metrics[3][4]]\n",
    "            metrics_df.loc[row_index] = row\n",
    "            print(metrics_df.loc[row_index])\n",
    "    \n",
    "        else:\n",
    "            row = [dataset_name, label_name, metrics[0][4], metrics[1][4], None, None]\n",
    "            metrics_df.loc[row_index] = row\n",
    "            print(metrics_df.loc[row_index])\n",
    "            \n",
    "rounded_df = metrics_df.round(2)\n",
    "with open('point_coverage.tex', 'w') as f:\n",
    "    f.write(rounded_df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdl_2022f_env",
   "language": "python",
   "name": "bdl_2022f_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
