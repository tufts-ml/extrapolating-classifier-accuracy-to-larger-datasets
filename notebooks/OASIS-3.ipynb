{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "import os\n",
    "import re\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from finetune_3D import *\n",
    "from logistic_regression import *\n",
    "from models import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_experiment('/cluster/home/eharve06/extrapolating-classifier-accuracy-to-bigger-datasets/experiments/WMD/n=414_random_state=3001.csv')\n",
    "print(open('/cluster/home/eharve06/extrapolating-classifier-accuracy-to-bigger-datasets/experiments/WMD/n=414_random_state=3001.txt').read())\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.epoch.to_list(), df.train_loss.to_list())\n",
    "plt.plot(df.epoch.to_list(), df.val_loss.to_list())\n",
    "plt.plot(df.epoch.to_list(), df.test_loss.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.epoch.to_list(), np.array(df.train_auroc.to_list())[:,0])\n",
    "plt.plot(df.epoch.to_list(), np.array(df.val_auroc.to_list())[:,0])\n",
    "plt.plot(df.epoch.to_list(), np.array(df.test_auroc.to_list())[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_performance = np.array(df.val_loss.to_list())\n",
    "averaged_performance = np.array([sum(val_performance[index-30:index]) for index in range(30, len(val_performance))])\n",
    "print(val_performance.shape)\n",
    "print('best epoch: {}'.format(30+np.argmin(averaged_performance)))\n",
    "print('val_auroc: {}'.format(df.val_auroc.to_list()[30+np.argmin(averaged_performance)]))\n",
    "print('test_auroc: {}'.format(df.test_auroc.to_list()[30+np.argmin(averaged_performance)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['n', 'random_state', 'train_BA', 'train_auroc', 'val_BA', 'val_auroc', 'test_BA', 'test_auroc']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "ns = [60, 94, 147, 230, 360, 414, 475, 546, 627]\n",
    "ns = [60, 94, 147, 230, 360, 414, 475]\n",
    "random_states = [1001, 2001, 3001, 4001, 5001, 6001, 7001, 8001, 9001, 10001, 11001, 12001, 13001, 14001, 15001]\n",
    "experiments_path = '/cluster/home/eharve06/extrapolating-classifier-accuracy-to-bigger-datasets/experiments/WMD'\n",
    "\n",
    "for model_index, (n, random_state) in enumerate(itertools.product(ns, random_states)):    \n",
    "    temp_df = load_experiment('{}/n={}_random_state={}.csv'\\\n",
    "                         .format(experiments_path, n, random_state))\n",
    "    val_performance = np.array(temp_df.val_auroc.to_list())\n",
    "    averaged_performance = np.array([sum(val_performance[index-30:index]) for index in range(30, len(val_performance))])\n",
    "    #averaged_performance[np.all(np.array(temp_df.train_auroc.to_list())[30:] < val_performance[30:], axis=-1)] = 0\n",
    "    train_loss, train_BA, train_auroc, val_loss, val_BA, val_auroc, test_loss, test_BA, test_auroc = temp_df.iloc[30+np.argmax(averaged_performance)].to_list()[1:]\n",
    "    row = [n, random_state, train_BA, train_auroc, val_BA, val_auroc, test_BA, test_auroc]\n",
    "    df.loc[model_index] = row\n",
    "    print('best epoch: {}'.format(30+np.argmax(averaged_performance)))\n",
    "    print('val_loss: {:0.4f}'.format(temp_df.val_loss.to_list()[30+np.argmax(averaged_performance)]))\n",
    "    print(open('{}/n={}_random_state={}.txt'.format(experiments_path, n, random_state)).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alpha(n):\n",
    "    if n <= 360:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.3\n",
    "\n",
    "def plot_experiment(df, labels, random_states=[1001, 2001, 3001]):\n",
    "    df = df[df.random_state.isin(random_states)]\n",
    "    colors = ['#2ca02c', '#ff7f0e', '#9467bd', '#1f77b4', '#d62728', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf', '#ff9896', '#aec7e8', '#ff0000', '#00ff00', '#0000ff']\n",
    "    ncols = len(labels) if len(labels) < 4 else 4\n",
    "    nrows = math.ceil(len(labels)/4)\n",
    "    fig, axs = plt.subplots(ncols=ncols, nrows=nrows, figsize=(ncols*4, nrows*3))\n",
    "    for label_index, _ in enumerate(labels):       \n",
    "        for color, random_state in zip(colors, random_states):\n",
    "            # Plot data\n",
    "            temp_df = df[df.random_state==random_state]\n",
    "            np.array(axs).flatten()[label_index]\\\n",
    "            .scatter(temp_df.n.to_numpy(),\n",
    "                     np.array(temp_df.test_auroc.to_list())[:,label_index],\n",
    "                     color = color,\n",
    "                     alpha=list(map(get_alpha, df.n[df.random_state==random_state].to_list())),\n",
    "                     label='seed {}'.format(random_state))\n",
    "        np.array(axs).flatten()[label_index]\\\n",
    "        .set_xlim([50, 30000])\n",
    "        np.array(axs).flatten()[label_index]\\\n",
    "        .set_ylim([0.5, 1.0])\n",
    "        np.array(axs).flatten()[label_index]\\\n",
    "        .set_xscale('log')\n",
    "        np.array(axs).flatten()[label_index]\\\n",
    "        .set_xlabel('Number of training samples')\n",
    "        np.array(axs).flatten()[label_index]\\\n",
    "        .set_ylabel('{} AUROC'.format(labels[label_index]))\n",
    "        np.array(axs).flatten()[label_index]\\\n",
    "        .legend()\n",
    "        np.array(axs).flatten()[label_index]\\\n",
    "        .grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_experiment(df, ['WMD'], random_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby('n').agg(lambda x: list(x))\n",
    "df.test_auroc = df.test_auroc.apply(lambda x: np.array([np.mean(x)]))\n",
    "df.random_state = df.random_state.apply(lambda x: 'mean')\n",
    "df = df.reset_index()\n",
    "plot_experiment(df, ['Alzheimerâ€™s'], ['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdl_2022f_env",
   "language": "python",
   "name": "bdl_2022f_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
